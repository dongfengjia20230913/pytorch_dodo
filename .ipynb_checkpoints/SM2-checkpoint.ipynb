{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 获取数据集"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fashion-MNIST中⼀一共包括了了10个类别，分别为t-shirt（T恤）、 trouser（裤⼦子）、 pullover（套衫）、\n",
    "dress（连⾐衣裙）、 coat（外套）、 sandal（凉鞋）、 shirt（衬衫）、 sneaker（运动鞋）、\n",
    "bag（包）和ankle boot（短靴）。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import sys\n",
    "sys.path.append('..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_train =torchvision.datasets.FashionMNIST(root='./Datasets/FashionMNIST',train=True, download=True, transform=transforms.ToTensor())\n",
    "mnist_test =torchvision.datasets.FashionMNIST(root='./Datasets/FashionMNIST',train=False, download=True, transform=transforms.ToTensor())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "FashionMNIST返回一个Dataset对象， Dataset是 PyTorch 中用来表示数据集的一个抽象类。如果数据集用这个类来表示，至少覆写下面两个方法\n",
    "1. __len__：数据集大小\n",
    "2. __getitem__：实现这个方法后，可以通过下标的方式（ dataset[i] ）的来取得第 i 个数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset FashionMNIST\n",
       "    Number of datapoints: 60000\n",
       "    Root location: ./Datasets/FashionMNIST\n",
       "    Split: Train\n",
       "    StandardTransform\n",
       "Transform: ToTensor()"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "因此，我们可以通过下标的方式返回单个数据数据进行查看"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "features, labels = mnist_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1, 28, 28]), 9)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features.shape, labels#第一个图片对应的尺寸和标签"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "数据中存储的是各个图片对应的标签，为了展示，转化成对应的类名"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_fashion_mnist_labels(labels):\n",
    "    text_labels = ['t-shirt', 'trouser', 'pullover', 'dress','coat','sandal', 'shirt', 'sneaker', 'bag', 'ankleboot']\n",
    "    return [text_labels[int(i)] for i in labels]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "显示图片"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_fashion_mnist(images, labels):\n",
    "    _, figs = plt.subplots(1, len(images), figsize=(12, 12))\n",
    "    for f, img, lbl in zip(figs, images, labels):\n",
    "        f.imshow(img.view((28, 28)).numpy())\n",
    "        f.set_title(lbl)\n",
    "        f.axes.get_xaxis().set_visible(False)\n",
    "        f.axes.get_yaxis().set_visible(False)\n",
    "    plt.show()\n",
    "X, y = [], []\n",
    "for i in range(10):\n",
    "    X.append(mnist_train[i][0])\n",
    "    y.append(mnist_train[i][1])\n",
    "#show_fashion_mnist(X, get_fashion_mnist_labels(y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "为了批量化训练和测试，我们将数据改成批量化形式，提高训练和测试速度"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 256\n",
    "num_workers = 4\n",
    "train_iter = torch.utils.data.DataLoader(mnist_train,batch_size=batch_size, shuffle=True, num_workers=num_workers)\n",
    "test_iter = torch.utils.data.DataLoader(mnist_test,batch_size=batch_size, shuffle=False, num_workers=num_workers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 初始化模型权重参数"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "使用回归的方式预测图片大小，每个图片28x28个像素，表示网络的输入是28个值，输出是10个值，根据矩阵相乘的概念的，W的形状应该是[784, 10],以保证X*W的输出是10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], requires_grad=True)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "num_inputs = 784 #单个图片像素个数 28x28\n",
    "num_outputs = 10 #分类格式\n",
    "\n",
    "W  = torch.tensor(np.random.normal(0,0.01, (num_inputs, num_outputs)), dtype = torch.float)\n",
    "b = torch.zeros(num_outputs, dtype = torch.float)\n",
    "W.requires_grad_(requires_grad=True)\n",
    "b.requires_grad_(requires_grad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1, 784]), torch.Size([784, 10]), torch.Size([10]))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[0].view(-1, num_inputs).shape, W.shape,b.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 10])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xw = torch.mm(X[0].view(-1, num_inputs), W) #矩阵相乘,得到10个输出（因为有10个分类）\n",
    "xw.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### softmax运算"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "softmax函数，又称归一化指数函数。\n",
    "它是二分类函数sigmoid在多分类上的推广，目的是将多分类的结果以概率的形式展现出来。函数定义方式如下："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax(X):\n",
    "    X_exp = X.exp()\n",
    "    partition = X_exp.sum(dim=1, keepdim=True)\n",
    "    return X_exp / partition # 这⾥里里应⽤用了了⼴广播机制"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.1186, 0.1177, 0.0787, 0.0816, 0.1333, 0.1023, 0.0879, 0.1101, 0.0886,\n",
       "         0.0810]], grad_fn=<DivBackward0>)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output = softmax(xw)#转程分类概率输出格式\n",
    "output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "每个图片的网络输出经过softmax处理，得到10个范围在[0,1]的输出，且各个输出的和为1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 定义模型"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "根据以上步骤的验证，很容易定义网络的结构"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def net(X):\n",
    "    xw = torch.mm(X.view(-1, num_inputs), W) +b # y = X.W+B\n",
    "    return softmax(xw)#输出分类概率值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.1186, 0.1177, 0.0787, 0.0816, 0.1333, 0.1023, 0.0879, 0.1101, 0.0886,\n",
       "         0.0810]], grad_fn=<DivBackward0>)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output = net(X[0])\n",
    "output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 定义损失函数"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "使用gather函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0810]], grad_fn=<GatherBackward>)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_hat = output #两个图片预测的对应的3个分类的阈值\n",
    "y = torch.LongTensor([9])#图片0对应的真实标签id\n",
    "y_hat.gather(1, y.view(-1, 1))#根据真实标签，获取标签位置出的阈值"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "交叉熵损失函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_entropy(y_hat, y):\n",
    "    return - torch.log(y_hat.gather(1, y.view(-1, 1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(y_hat, y):\n",
    "    return (y_hat.argmax(dim=1) == y).float().mean().item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.1186, 0.1177, 0.0787, 0.0816, 0.1333, 0.1023, 0.0879, 0.1101, 0.0886,\n",
       "         0.0810]], grad_fn=<DivBackward0>)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_hat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([4])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_hat.argmax(dim=1)#输出的10个分类阈值，最大值对应的标签id，通过改方法，可以得到预测值对应的预测标签"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sgd(params, lr, batch_size): \n",
    "    for param in params:\n",
    "        param.data -= lr * param.grad / batch_size # 注意这⾥里里更更改\n",
    "        \n",
    "def evaluate_accuracy(data_iter, net):\n",
    "    acc_sum, n = 0.0, 0\n",
    "    for X, y in data_iter:\n",
    "        acc_sum += (net(X).argmax(dim=1) == y).float().sum().item()\n",
    "        n += y.shape[0]\n",
    "    return acc_sum / n\n",
    "\n",
    "\n",
    "def train_ch3(net, train_iter, test_iter, loss, num_epochs, batch_size, params=None, lr=None, optimizer=None):\n",
    "    for epoch in range(num_epochs):\n",
    "        train_l_sum, train_acc_sum, n = 0.0, 0.0, 0\n",
    "        for X, y in train_iter:\n",
    "            y_hat = net(X)\n",
    "            l = loss(y_hat, y).sum()\n",
    "            # 梯度清零\n",
    "            if optimizer is not None:\n",
    "                optimizer.zero_grad()\n",
    "            elif params is not None and params[0].grad is not None:\n",
    "                for param in params:\n",
    "                    param.grad.data.zero_()\n",
    "            l.backward()\n",
    "            if optimizer is None:\n",
    "                sgd(params, lr, batch_size)\n",
    "            else:\n",
    "                optimizer.step() # “softmax回归的简洁实现”⼀一节将⽤用到\n",
    "            train_l_sum += l.item()\n",
    "            train_acc_sum += (y_hat.argmax(dim=1) ==y).sum().item()\n",
    "            n += y.shape[0]\n",
    "        test_acc = evaluate_accuracy(test_iter, net)\n",
    "        print('epoch %d, loss %.4f, train acc %.3f, test acc %.3f'% (epoch + 1, train_l_sum / n, train_acc_sum / n,test_acc))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1, loss 1.3670, train acc 0.645, test acc 0.685\n",
      "epoch 2, loss 0.9163, train acc 0.718, test acc 0.722\n",
      "epoch 3, loss 0.8029, train acc 0.749, test acc 0.750\n",
      "epoch 4, loss 0.7429, train acc 0.768, test acc 0.759\n",
      "epoch 5, loss 0.7034, train acc 0.779, test acc 0.771\n",
      "epoch 6, loss 0.6746, train acc 0.788, test acc 0.779\n",
      "epoch 7, loss 0.6523, train acc 0.795, test acc 0.784\n",
      "epoch 8, loss 0.6344, train acc 0.800, test acc 0.787\n",
      "epoch 9, loss 0.6194, train acc 0.803, test acc 0.792\n",
      "epoch 10, loss 0.6068, train acc 0.807, test acc 0.795\n",
      "epoch 11, loss 0.5958, train acc 0.809, test acc 0.799\n",
      "epoch 12, loss 0.5864, train acc 0.812, test acc 0.798\n",
      "epoch 13, loss 0.5780, train acc 0.814, test acc 0.804\n",
      "epoch 14, loss 0.5705, train acc 0.817, test acc 0.804\n",
      "epoch 15, loss 0.5636, train acc 0.818, test acc 0.808\n",
      "epoch 16, loss 0.5575, train acc 0.820, test acc 0.809\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 30\n",
    "lr = 0.01\n",
    "train_ch3(net, train_iter, test_iter, cross_entropy, num_epochs, batch_size, [W, b], lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "整体的准确率在82%左右"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 整合代码"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.SlowFast import SlowFast1\n",
    "from utils.SlowFast import get_fashion_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1, loss 1.3694, train acc 0.646, test acc 0.684\n",
      "epoch 2, loss 0.9173, train acc 0.716, test acc 0.727\n",
      "epoch 3, loss 0.8033, train acc 0.750, test acc 0.748\n",
      "epoch 4, loss 0.7429, train acc 0.768, test acc 0.760\n",
      "epoch 5, loss 0.7031, train acc 0.779, test acc 0.770\n",
      "epoch 6, loss 0.6742, train acc 0.789, test acc 0.780\n",
      "epoch 7, loss 0.6520, train acc 0.796, test acc 0.783\n",
      "epoch 8, loss 0.6339, train acc 0.799, test acc 0.788\n",
      "epoch 9, loss 0.6191, train acc 0.804, test acc 0.793\n",
      "epoch 10, loss 0.6064, train acc 0.807, test acc 0.797\n",
      "epoch 11, loss 0.5954, train acc 0.810, test acc 0.797\n",
      "epoch 12, loss 0.5859, train acc 0.813, test acc 0.800\n",
      "epoch 13, loss 0.5775, train acc 0.814, test acc 0.804\n",
      "epoch 14, loss 0.5700, train acc 0.817, test acc 0.805\n",
      "epoch 15, loss 0.5632, train acc 0.819, test acc 0.807\n",
      "epoch 16, loss 0.5571, train acc 0.820, test acc 0.808\n",
      "epoch 17, loss 0.5514, train acc 0.821, test acc 0.810\n",
      "epoch 18, loss 0.5462, train acc 0.823, test acc 0.810\n",
      "epoch 19, loss 0.5416, train acc 0.824, test acc 0.812\n",
      "epoch 20, loss 0.5372, train acc 0.825, test acc 0.814\n",
      "epoch 21, loss 0.5331, train acc 0.826, test acc 0.813\n",
      "epoch 22, loss 0.5293, train acc 0.827, test acc 0.816\n",
      "epoch 23, loss 0.5257, train acc 0.828, test acc 0.815\n",
      "epoch 24, loss 0.5224, train acc 0.829, test acc 0.816\n",
      "epoch 25, loss 0.5192, train acc 0.829, test acc 0.816\n",
      "epoch 26, loss 0.5161, train acc 0.830, test acc 0.819\n",
      "epoch 27, loss 0.5133, train acc 0.832, test acc 0.819\n",
      "epoch 28, loss 0.5108, train acc 0.832, test acc 0.819\n",
      "epoch 29, loss 0.5082, train acc 0.832, test acc 0.821\n",
      "epoch 30, loss 0.5058, train acc 0.834, test acc 0.820\n"
     ]
    }
   ],
   "source": [
    "slowfast1 = SlowFast1(image_size = 28*28, class_nums = 10)\n",
    "batch_size = 256\n",
    "train_iter, test_iter = get_fashion_data(img_dir='./Datasets/FashionMNIST', batch_size = batch_size)\n",
    "num_epochs = 30\n",
    "params = [slowfast1.W, slowfast1.b]\n",
    "lr = 0.01\n",
    "slowfast1.train(slowfast1.net, train_iter, test_iter, slowfast1.cross_entropy, num_epochs, batch_size, params, lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
